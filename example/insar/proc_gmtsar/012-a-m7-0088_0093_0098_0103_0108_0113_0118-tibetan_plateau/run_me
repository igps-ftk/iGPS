#!/bin/sh

path_old=`pwd`
echo "# path_old $path_old"

echo -e "\n#set esa_data variable"
echo "export esa_data=../../esa.data/   #for bash"
export esa_data=../../esa.data/

echo -e "\n#download Sentinel-1 SLC files from ASF"
echo cd $esa_data/s1/by.track/A012/
cd $esa_data/s1/by.track/A012/
echo pwd
echo "#`pwd`"
echo "#  get files from ASF Vertex Python downloader"
echo sh_asf_s1_get_slc_py -file download-all-2023-05-09_03-45-55.py -ac earthdata.conf
echo "#  get files from SLC list file"
echo sh_asf_s1_get_slc_py -file s1_a012_used.list -type list -ac earthdata.conf
echo "#  get files from ESA meta4 file"
echo sh_asf_s1_get_slc_py -file products.meta4 -type meta4 -ac erathdata.conf
echo "#  query and download files for a region using ASF API"
echo sh_asf_s1_get_slc_roi -roi ${iGPS}/tables/roi_line_a12.kml -orbit ASCENDING -ac earthdata.conf


echo cd $path_old
cd $path_old

echo -e "\n#get orbit files"
ymds=`find $esa_data/s1/ -maxdepth 1 -name "S1?_IW_SLC__1S?V_20*.zip" | sort | awk -F_ '{print substr($6,1,8)}' | sort | uniq`
for ymd in $ymds; do
  echo sh_esa_s1_get_aux_orb_gnss -d $ymd
  #echo sh_esa_s1_get_aux_orb_gnss -d $ymd | sh
  #exit
done

echo -e "\n#extract *.manifest.safe files"
echo sh_s1_unzip_manifest -p ${esa_data}/s1/by.track/A012 -o ${esa_data}/metainfo/manifest.safe/A012
#sh_s1_unzip_manifest -p ${esa_data}/s1/by.track/A012 -o ${esa_data}/metainfo/manifest.safe/A012

echo -e "\n#set esa_unzip variable"
echo "export esa_unzip=../../esa_unzip/   #for bash"
export esa_unzip=../../esa_unzip/

echo -e "\n#get SLC files to process"
echo sh_s1_expt_safe -s ../../esa.data/metainfo/manifest.safe/
#sh_s1_expt_safe -s ../../esa.data/metainfo/manifest.safe/

echo -e "\n#extract SLC zip files to temporary location (esa_unzip)"
echo sh_s1_unzip -file input.lst.ok
#sh_s1_unzip -file input.lst.ok

echo mkdir -p F1 F2 F3
mkdir -p F1 F2 F3

echo -e "\n#run TSA for iw1 ..."
echo cd F1
cd F1
echo pwd
echo "#`pwd`"
echo sh_s1_run_tsa -file ../input.lst.ok -proc_type interseismic -iw iw1
#sh_s1_run_tsa -file ../input.lst.ok -proc_type interseismic -iw iw1


echo cd $path_old
cd $path_old
echo -e "\n#run TSA for iw2 ..."
echo cd F2
cd F2
echo pwd
echo "#`pwd`"
echo sh_s1_run_tsa -file ../input.lst.ok -proc_type interseismic -iw iw2
#sh_s1_run_tsa -file ../input.lst.ok -proc_type interseismic -iw iw2


echo cd $path_old
cd $path_old
echo -e "\n#run TSA for iw3 ..."
echo cd F3
cd F3
echo pwd
echo "#`pwd`"
echo sh_s1_run_tsa -file ../input.lst.ok -proc_type interseismic -iw iw3
#sh_s1_run_tsa -file ../input.lst.ok -proc_type interseismic -iw iw3

echo -e "\n**ONLY a random subset of interferograms will be processed for each subswath."
echo "     Therefore, one should manually copy one case (e.g., F1/intf.in)"
echo "     to the other two (e.g., F2/ and F3/)."

echo cd $path_old
cd $path_old
echo -e "\n#prepare files for merging iw1+iw2+iw3 ..."
echo sh_s1_prep_f123
#sh_s1_prep_f123
echo cd f123
cd f123
echo pwd
echo "#`pwd`"
wc -l intf.in.f123* batch_tops.config

echo -e "\n#run merging ..."
echo merge_batch.csh intf.in.f123.1 batch_tops.config
#merge_batch.csh intf.in.f123.1 batch_tops.config
echo "*NOTE*: run this at least once to create the trans.dat file!"

echo -e "\nget remaining interferograms to merge ..."
echo sh_s1_prep_f123_in
#sh_s1_prep_f123_in
echo "#  will create intf.in.f123.1"
wc -l intf.in.f123*

echo -e "\n#run merging for remaining interferograms ..."
echo merge_batch2.csh intf.in.f123.1 intf.in.f123.2 batch_tops.config
#merge_batch2.csh intf.in.f123.1 intf.in.f123.2 batch_tops.config

echo -e "\n#run merging in parallel mode in single PC ..."
echo merge_batch2_parallel.csh intf.in.f123.1 intf.in.f123.2 batch_tops.config 3
#merge_batch2_parallel.csh intf.in.f123.1 intf.in.f123.2 batch_tops.config 3

echo -e "\n#run merging with SLURM in a cluster ..."
echo sh_slurm_merge -master intf.in.f123.1 -file intf.in.f123.2 -delay 60 -nmax_job 100
#sh_slurm_merge

echo -e "\n#which interferograms had been processed?"
echo sh_sar_cp_intf_png
#sh_sar_cp_intf_png

#return to the root processing directory
cd $path_old
echo -e "\n#perform GACOS correction to unwrapped interferograms"
echo "#  1)get the list of dates to generate GACOS correction"
echo "sh_sar_gacos_time" 
sh_sar_gacos_time

echo "#  2)download the binary file from GACOS webpage, saving into f123/tgz/"
#manually download the GACOS files

echo "#  3)unpack the downloaded compressed files"
cd f123
echo pwd
echo "#`pwd`"
echo sh_sar_gacos_tgz_unzip
#sh_sar_gacos_tgz_unzip

echo "#  4)convert binary ztd to NetCDF"
echo sh_sar_gacos_ztd2ll
#sh_sar_gacos_ztd2ll

echo "#  5)convert ztd from wgs-84 to radar coordinate"
echo sh_sar_gacos_ll2ra
#sh_sar_gacos_ll2ra

echo "#  6)calculate ztd difference for interferograms"
echo sh_sar_gacos_intf_all
#sh_sar_gacos_intf_all

echo "#  7)apply gacos correction"
echo sh_sar_gacos_apply_intf_add
#sh_sar_gacos_apply_intf_add


echo -e "\n#resample interferograms to lower resolution"
echo sh_sar_intf_all_resample
#sh_sar_intf_all_resample #will create intf_all_x2

echo -e "\n#generate interferograms collections using different temporal baselines"
echo "sh_sar_prep_sbases -t '0 1,36 1,72  ,366  367, 730'  #-min,max number of days"
#sh_sar_prep_sbases -t '0 1,36 1,72  ,366  367, 730'
# will create b0-/ b1-36/ b1-72/ b0-366/ b367-/ b730-/*.tab

echo -e "\n#prepare files (intf.tab, scene.tab) for SBAS"
echo "cp b0-/*.tab ."
echo "cp b1-72/*.tab .  #use temporal baselines <=72 days"
echo "cp b367-/*.tab .  #use temporal baselines larger than one year (366 days)"
echo sar_sbas_tab_from_png
#sar_sbas_tab_from_png
#or,
echo sh_sar_sbas_tab_by_png
#sh_sar_sbas_tab_by_png
wc -l intf.tab scene.tab

echo -e "\n#run SBAS in parallel mode"
echo sh_sar_call_sbas -r 3 -i intf_all -t1 0 -t2 9999 -p y
echo sh_sar_call_sbas -r 4 -i intf_all_x2_gacos -p y
#sh_sar_call_sbas -r 3 -p y
echo e.g., output to sbas.4.9.0001.9999.20150627.20220930.053.0393.01.___

echo -e "\n#run SBAS only using data during 2017-2022"
echo sar_sbas_tab_from_png --y1=17 --y2=22
echo -e "\n#run SBAS only using data after 2020-07-23"
echo sar_sbas_tab_from_png --y1=20 --d1=206
echo -e "\n#run SBAS only using data before 2020-07-23"
echo sar_sbas_tab_from_png --y2=20 --d2=204


cd sbas.4.9.0001.9999.20150627.20220930.053.0393.01.___
echo pwd
echo "#`pwd`"
echo -e "\n#Convert InSAR LOS velcoity to GNSS velocity (LOS) frame"
echo "#  first, convert GNSS horizontal velocity to InSAR LOS direction"
echo "sh_gnss_vel2los"
#sh_gnss_vel2los

echo "#  then, rotate InSAR velocity to GNSS-LOS velocity"
echo sh_gnss_correct_insar_vel
#sh_gnss_correct_insar_vel 

echo -e "\n#create profile lines"
echo "mkdir -p p.fa_atf_2"
echo profile_vector_auto --file=${iGPS}/tables/fa_atf.psxy --ofile=p.fa_atf_2/profiles_auto.psxy --length=1300 --strike=2
#profile_vector_auto --file=${iGPS}/tables/fa_atf.psxy --ofile=p.fa_atf_2/profiles_auto.psxy --length=1300 --strike=2


echo -e "\n#create velocity profiles from InSAR XYZ file"
echo sar_los_profile_auto --ffile=${iGPS}/tables/fa_atf.psxy --pfile=p.fa_atf_2/profiles_auto.psxy --vfile=vel_mask_ll_gnss3.xyze --opath=p.fa_atf_2
#sar_los_profile_auto --ffile=${iGPS}/tables/fa_atf.psxy --pfile=p.fa_atf_2/profiles_auto.psxy --vfile=vel_mask_ll_gnss3.xyze --opath=p.fa_atf_2


echo -e "\n#create profile plots "
echo sh_sar_plot_vel_profile 
#sh_sar_plot_vel_profile 
echo "#  output to pp.fa_atf_2"
echo sh_sar_plot_vel_profile -p p.fa_atf_2 -n 29,13 -R -R-200/1100/-20/20
echo "#  output to pp.fa_atf_2_userAxis"
