#!/bin/bash

# Name:
#   sh_slurm_merge_batch
#

# Purpose:
#   Queue gamit tasks to slurmd.

# Example:
#

# Modifications:
#

# Algorithm:
#

# Dependency:
#
PROG=sh_slurm_merge_batch

timestamp=`date | sed -e "s/ /_/g" | sed -e "s/:/-/g"`

usage_of_it(){
cat <<eob
$PROG
|_Submit merging-and-unwrapping jobs to SLURM.
|+
  -files from sh_s1_prep_f123 (intf.in.f123.1)
  -file from sh_s1_prep_f123_in (intf.in.f123.2)
  -merge_batch2.csh
|<
  [-m|-master intf.in.f123.1]
  [-f|-file intf.in.f123.2]
  [-c|-config batch_tops.config]
  [-d|-delay DELAY_BETWEEN_SUBMITTING_SECONDS]
  [-o|-overwrite OVERWRITE_EXISTING_SUBMIT]
  [-n|-nmax_job NUMBER_OF_MAXIMUM_JOBS_TO_SUBMIT]
|e.g.,
  ${PROG}
  ${PROG} -d 90 -m intf.in.f123.1 -f intf.in.f123.2 -nmax_job 100
(c)iGPS (https://github.com/igps-ftk/)
eob
}

#if called by crontab
if [ -t 0 ]; then
    interactive=1
else
    interactive=0
    . ${HOME}/.bashrc
fi
#echo "interactive $interactive"
#if [ $interactive -eq 0 ]; then
#  . ${HOME}/.bashrc
#fi

#the directory to hold the interferograms, e.g. f123.1
COMB_DIR=`pwd`
ROOT_DIR=${COMB_DIR}/..

#--
# |-F1/
# |  |-intf_all/
# |  |-raw/
# |
# |-F2/
# |  |-intf_all/
# |  |-raw/
# |
# |-F3/
# |  |-intf_all/
# |  |-raw/
# |
# |-f123/ (merging directory)
# |  |-batch_tops.config
# |  |-dem.grd
# |  |-intf.in.f123
# |  |-raln.grd
# |  |-ralt.grd
# |  |-trans.dat

if [ ! -s dem.grd ]; then
  echo -e "[$PROG]\033[1;33;41mERROR\033[0m: no/wrong dem.grd file!!"
  exit 1
fi


#session name
tmp=`dirname ${COMB_DIR}/test.txt`
#echo tmp is $tmp
#echo COMB_DIR is $COMB_DIR
PROC_ID=`dirname ${tmp} | awk -F\/ '{print $NF}'`
echo PROC_ID is $PROC_ID


#gamit processing directory, e.g.
PROC_DIR=/home/tianyf/gsar/
echo "*Note: the daily processing will be in ${PROC_DIR}/temp/"

#Archive H-file directory
ARCHIVE_DIR=${COMB_DIR}/intf_all
mkdir -p $ARCHIVE_DIR

#Temporary files directory
TMP_DIR=`pwd`


overwrite=n
file_intf_in=intf.in.f123.2
file_master=intf.in.f123.1
batch_config=batch_tops.config
delay=30
nmax_job=9999

while [ "$1" != "" ]; do
  case $1 in
    -f|-file)
      file_intf_in=$2
      ;;
    -m|-master)
      file_master=$2
      ;;
    -c|-config)
      batch_config=$2
      ;;
    -d|-delay)
      delay=$2
      ;;
    -o|-overwrite)
      overwrite=$2
      ;;
    -n|-nmax|-nmax_job)
      nmax_job=$2
      ;;
    -h|-help|--help)
      usage_of_it
      exit 1
      ;;
    *)
      echo -e "[$PROG]\033[1;33;41mERROR\033[0m: invalid option ($1)!!"
      usage_of_it
      ;;
  esac
  shift 2
done

#exit

#file_master=intf.in.f123.1
if [ ! -s $file_master ]; then
  usage_of_it
  echo -e "[$PROG]\033[1;33;41mERROR\033[0m: master file not exist ($file_master)!!"
  echo "[$PROG]HELP: use sh_s1_prep_f123_in to create input files."
  exit 1
fi

#file_intf_in=intf.in.f123.2
if [ ! -s $file_intf_in ]; then
  usage_of_it
  echo -e "[$PROG]\033[1;33;41mERROR\033[0m: input file not exist ($file_intf_in)!!"
  echo "[$PROG]HELP: use sh_s1_prep_f123_in to create input files."
  exit 1
fi

#batch_config=batch_tops.config
if [ ! -s $batch_config ]; then
  echo -e "[$PROG]\033[1;33;41mERROR\033[0m: processing configuation file not exist ($batch_config)!!"
  exit 1
fi

n_job=0
n_skip=0
n_new=0
while read line; do
    if [ $n_job -gt $nmax_job ]; then
      echo "[$PROG]INFO: maximum number of job reached ($nmax_job)."
      break
    fi
    date1=`echo $line |awk -F":" '{print $2}'|cut -c 4-11`
    date2=`echo $line |awk -F":" '{print $3}'|cut -c 4-11`
    dir_name=`echo $line | awk -F, '{print $1}' | awk -F: '{print $1}' | awk -F"/" '{print $(NF-1)}'`


    cmdfile=slurm_merge_batch_${date1}_${date2}.cmd

    echo "${ARCHIVE_DIR}/${dir_name}/unwrap_mask.grd"
    #exit
    if [ -s "${ARCHIVE_DIR}/${dir_name}/unwrap_mask.grd" ]; then
      echo overwrite $overwrite
      if [ "$overwrite" == "n" ]; then
        echo "[$PROG]INFO:output already exist (${dir_name})! Skipped."
        n_skip=`expr $n_skip + 1`
        continue
      else
        echo "[$PROG]INFO: >$overwrite<"
      fi
    else
      if [ -s "$cmdfile" -a "$overwrite" == "n" ]; then
        echo "[$PROG]INFO:already queued(${date1}_${date2})! Skipped."
        n_skip=`expr $n_skip + 1`
        continue
      fi
    fi

    logfile="slurm_merge_batch_"$date1"_"$date2".log"
    infile="slurm_merge_batch_"$date1"_"$date2".in"

    echo $line > $infile
    #cmdfile=merge_batch_${date1}_${date2}.cmd
    echo "#!/bin/bash" > $cmdfile
    echo "hostname" >> $cmdfile
    echo "which sbas" >> $cmdfile
    echo 'echo $PATH' >> $cmdfile
    echo "merge_batch2.csh $file_master $infile $batch_config >& $logfile" >> $cmdfile

    #dir_name=`echo $line | awk -F, '{print $1}' | awk -F: '{print $1}' | awk -F"/" '{print $(NF-1)}'`
    echo dir_name $dir_name
    file_t=${COMB_DIR}/slurm_merge_batch_${dir_name}.sh
    #check whether already done
    #

    tmp=`date | sed -e 's/ /_/g' | sed -e 's/:/-/g'`


    echo "#!/bin/bash" > $file_t
    echo "#SBATCH --job-name=${dir_name}-${COMB_ID}-${PROC_ID}" >> $file_t
    echo "#SBATCH --nodes=1" >> $file_t
    echo "#SBATCH --ntasks=1" >> $file_t
    echo "#SBATCH --cpus-per-task=1" >> $file_t
    echo "pwd; hostname; date" >> $file_t


    path_t=${PROC_DIR}/temp/${tmp}-${PROC_ID}-${dir_name}
    echo "mkdir -p $path_t " >> $file_t
    # make links
    echo "cd ${path_t}" >> $file_t
    echo "ln -s ${ROOT_DIR}/F1" >> $file_t
    echo "ln -s ${ROOT_DIR}/F2" >> $file_t
    echo "ln -s ${ROOT_DIR}/F3" >> $file_t
    echo "mkdir -p f123" >> $file_t
    echo "cd f123" >> $file_t
    echo "pwd" >> $file_t

    echo "ln -s ${COMB_DIR}/batch_tops.config" >> $file_t
    echo "ln -s ${COMB_DIR}/dem.grd" >> $file_t
    echo "ln -s ${COMB_DIR}/raln.grd" >> $file_t
    echo "ln -s ${COMB_DIR}/ralt.grd" >> $file_t
    echo "ln -s ${COMB_DIR}/trans.dat" >> $file_t
    echo "ln -s ${COMB_DIR}/$cmdfile" >> $file_t
    echo "ln -s ${COMB_DIR}/$infile" >> $file_t
    echo "ln -s ${COMB_DIR}/$file_master" >> $file_t



    echo 'date' >> $file_t
    echo '#sleep 3' >> $file_t
    echo "sh $cmdfile" >> $file_t

    echo "if [ -s \"${dir_name}/unwrap_mask.grd\" ]; then " >> $file_t
    #echo "  sh_sar_clean_intf $dir_name" >> $file_t
    echo "  sh_sar_clean_intf_more $dir_name" >> $file_t
    echo "  mv $dir_name ${ARCHIVE_DIR}/" >> $file_t
    echo "fi" >> $file_t

    echo 'date' >> $file_t
    echo "cp -f $logfile $COMB_DIR" >> $file_t

    echo $file_t
    #cat $file_t
    pwd
    #sleep 1
    sbatch $file_t
    n_new=`expr $n_new + 1`

    echo "[$PROG]INFO:waiting $delay seconds to submit next job ..."
    sleep $delay

    n_job=`expr $n_job + 1`
    #exit
done < $file_intf_in


#squeue
sinfo

echo "[$PROG]INFO: $n_new jobs submitted and $n_skip skipped."
echo "[$PROG]INFO: done."
